{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.ensemble import BaggingClassifier as knn_bagging\n",
    "from sklearn.linear_model import SGDClassifier as sgd\n",
    "from sklearn.linear_model import LogisticRegression as logistic_reg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import imblearn\n",
    "plt.style.use(\"dark_background\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_run = False\n",
    "\n",
    "has_tr_train = True\n",
    "has_tr_test = False\n",
    "has_tr_unc = False\n",
    "\n",
    "use_uncertain = True\n",
    "encoding_size = 512\n",
    "\n",
    "run_on_raw = True\n",
    "knn_neighbors = 11\n",
    "\n",
    "run_name = 'C23_C24_july_12_rerun_without_smote'#'c23_june_21' #'c23_c24_june_14'\n",
    "based_on = 'C23_C24_july_12_rerun_without_smote' #'finetuning_14_06_23_c23_c24_no_prevs_replacement_pos_train/test_lowdecay_20.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./out/12_07_redo-train.csv')\n",
    "df_test = pd.read_csv('./out/12_07_redo-val.csv')\n",
    "\n",
    "df_test['name']= df_test['name'].str.replace('pos-concat-val','pos-concat')\n",
    "df_train['name']= df_train['name'].str.replace('pos-upsampled-concat','pos-concat')\n",
    "df_test['name']= df_test['name'].str.replace('pos-upsampled-concat','pos-concat')\n",
    "df_test['name']= df_test['name'].str.replace('dataset/C','dataset/all/C')\n",
    "df_train = df_train[~df_train['name'].isin(df_test['name'])]\n",
    "\n",
    "if use_uncertain:\n",
    "    df_uncertain_test = pd.read_csv('./out/12_07_redo-test.csv')\n",
    "\n",
    "# df_test = pd.concat([pd.read_csv('./negs_test.csv'), pd.read_csv('./out/07_07_upsfix_supcon_upsample_test.csv')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vanessa/Dev/DATASETS/C23_C24_pos-concat/poz/img_poz_1996_07_09_09_01_00_79.png'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vanessa/Dev/DATASETS/C23_C24_pos-concat/neg/img_poz_2012_03_06_04_01_00_210.png'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if old_run:\n",
    "    cols_to_extract_no_tr  = ['useless1', 'part_of_quake','Year','month','day','event_idx','frame']\n",
    "else:\n",
    "    cols_to_extract_no_tr  = ['useless1','useless2', 'useless3', 'part_of_quake','Year','month','day','Hour','Minute','Seconds','frame']\n",
    "cols_to_extract_has_tr  = cols_to_extract_no_tr + ['transform']\n",
    "emb_cols = [f'{x}' for x in range(0,encoding_size)]\n",
    "# emb_cols = ['1', '3', '5', '7', '9', '11', '13', '15', '17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cols(df, has_tr):\n",
    "    if (has_tr):\n",
    "        df[cols_to_extract_has_tr] = df['name'].str.split('_', expand=True)\n",
    "        df.loc[df['transform'].isna(),'transform'] = '20'\n",
    "        df['transform'] = df['transform'].str.extract('(\\d+)', expand=False)\n",
    "        df['transform']=df['transform'].astype(int)\n",
    "    else:\n",
    "        df[cols_to_extract_no_tr] = df['name'].str.split('_', expand=True)\n",
    "    \n",
    "    df['frame'] = df['frame'].str.extract('(\\d+)', expand=False)\n",
    "    df['frame']=df['frame'].astype(int)\n",
    "    return df\n",
    "\n",
    "def set_custom_preds(df, predcol=''):\n",
    "    is_pos = 1 if df[predcol+'_preds'].mean() > 0.5 else 0\n",
    "    is_pos_any = 1 if df[predcol+'_preds'].any() else 0\n",
    "    df[f'avg_{predcol}_preds'] = is_pos\n",
    "    df[f'any_{predcol}_preds'] = is_pos_any\n",
    "    return df\n",
    "\n",
    "def set_preds(df_train, df_test, df_uncertain, preds_train, preds_test, preds_uncertain, clstype):\n",
    "    df_train[clstype+'_preds'] = preds_train\n",
    "    df_test[clstype+'_preds'] = preds_test\n",
    "    if use_uncertain:\n",
    "        df_uncertain[clstype+'_preds'] = preds_uncertain\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_159178/4211971329.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_tr_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_tr_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_uncertain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_uncertain_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_uncertain_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_tr_unc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_159178/2331656730.py\u001b[0m in \u001b[0;36mupdate_cols\u001b[0;34m(df, has_tr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhas_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_to_extract_has_tr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transform'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'transform'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'20'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transform'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transform'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(\\d+)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3598\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3600\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3601\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3639\u001b[0;31m                 \u001b[0mcheck_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3640\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3641\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mcheck_key_length\u001b[0;34m(columns, key, value)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# Missing keys in columns are represented as -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "df_train = update_cols(df_train, has_tr=has_tr_train)\n",
    "df_test = update_cols(df_test, has_tr=has_tr_test)\n",
    "if use_uncertain:\n",
    "    df_uncertain_test = update_cols(df_uncertain_test, has_tr=has_tr_unc)\n",
    "else:\n",
    "    df_uncertain_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train[(df_train['label'] == 1) & (df_train['transform'] == 20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not old_run:\n",
    "    df_train['date'] = pd.to_datetime(df_train[['Year', 'month', 'day', 'Hour','Minute','Seconds']])\n",
    "    df_train['date'].unique() \n",
    "    \n",
    "    df_test['date'] = pd.to_datetime(df_test[['Year', 'month', 'day', 'Hour','Minute','Seconds']])\n",
    "    df_test['date'].unique()\n",
    "\n",
    "    if use_uncertain:\n",
    "        df_uncertain_test['date'] = pd.to_datetime(df_uncertain_test[['Year', 'month', 'day', 'Hour','Minute','Seconds']])\n",
    "        df_uncertain_test['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_on_raw:\n",
    "    if (has_tr_train):\n",
    "        df_train = df_train[df_train['transform'] == 20]\n",
    "    if (has_tr_test):\n",
    "        df_test = df_test[df_test['transform'] == 20]\n",
    "    if use_uncertain:\n",
    "        if has_tr_unc:\n",
    "            df_uncertain_test = df_uncertain_test[df_uncertain_test['transform'] == 20]\n",
    "\n",
    "if (not has_tr_train and not has_tr_test):\n",
    "    run_on_raw = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2753\n",
      "2065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2622\n",
      "           1       0.74      0.08      0.14       186\n",
      "\n",
      "    accuracy                           0.94      2808\n",
      "   macro avg       0.84      0.54      0.55      2808\n",
      "weighted avg       0.92      0.94      0.91      2808\n",
      "\n",
      "[[2617    5]\n",
      " [ 172   14]]\n",
      "[[930  23]\n",
      " [ 63   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       953\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.92      1016\n",
      "   macro avg       0.47      0.49      0.48      1016\n",
      "weighted avg       0.88      0.92      0.90      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(df_train[emb_cols])\n",
    "scaled_test = scaler.transform(df_test[emb_cols])\n",
    "if use_uncertain:\n",
    "    scaled_uncertain = scaler.transform(df_uncertain_test[emb_cols])\n",
    "\n",
    "# X = scaled_train\n",
    "# y = df_train['label']\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.2)\n",
    "under = RandomUnderSampler(sampling_strategy=0.75)\n",
    "\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X, y = pipeline.fit_resample(scaled_train, df_train['label'])\n",
    "print (len([x for i,x in enumerate(y) if x == 0]))\n",
    "print (len([x for i,x in enumerate(y) if x == 1]))\n",
    "\n",
    "svc1 = SVC(C=0.005, kernel='poly')#, class_weight='balanced')\n",
    "svc1.fit(X, y)\n",
    "preds_train_lr = svc1.predict(scaled_train)\n",
    "preds_test_lr = svc1.predict(scaled_test)\n",
    "\n",
    "preds_unc_lr = None\n",
    "if use_uncertain:\n",
    "    preds_unc_lr = svc1.predict(scaled_uncertain)\n",
    "\n",
    "preds_y = svc1.predict(X)\n",
    "\n",
    "df_train, df_test = set_preds(df_train, df_test, df_uncertain_test, preds_train_lr, preds_test_lr, preds_unc_lr, f'svc_poly')\n",
    "\n",
    "\n",
    "print(classification_report(df_test['label'], preds_test_lr))\n",
    "print(confusion_matrix(df_test['label'], preds_test_lr))\n",
    "if use_uncertain:\n",
    "    print(confusion_matrix(df_uncertain_test['label'], preds_unc_lr))\n",
    "    print(classification_report(df_uncertain_test['label'], preds_unc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2622\n",
      "           1       0.74      0.08      0.14       186\n",
      "\n",
      "    accuracy                           0.94      2808\n",
      "   macro avg       0.84      0.54      0.55      2808\n",
      "weighted avg       0.92      0.94      0.91      2808\n",
      "\n",
      "[[2617    5]\n",
      " [ 172   14]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['label'], df_test['svc_poly_preds']))\n",
    "print(confusion_matrix(df_test['label'], df_test['svc_poly_preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[(df_test['svc_poly_preds']==1) & (df_test['label']==0)]['svc_poly_preds'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1996-07-09 09:01:00    19\n",
       "2001-04-06 19:13:00    16\n",
       "2001-09-24 09:35:00    11\n",
       "2002-07-23 00:27:00    14\n",
       "2012-03-05 19:27:00    21\n",
       "2012-03-06 07:52:00    13\n",
       "2012-07-04 09:47:00    19\n",
       "2012-07-06 13:26:00    17\n",
       "2013-11-08 04:20:00    20\n",
       "2015-03-11 16:11:00    16\n",
       "2015-09-28 14:53:00    20\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[(df_test['label']==1)].groupby(by='date').agg(lambda x: len(x))['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['date'].unique()) + len(df_test['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1996-07-09 09:01:00    19\n",
       "2001-04-06 19:13:00    16\n",
       "2001-09-24 09:35:00    11\n",
       "2002-07-23 00:27:00    14\n",
       "2012-03-05 19:27:00    19\n",
       "2012-03-06 07:52:00    11\n",
       "2012-07-04 09:47:00    17\n",
       "2012-07-06 13:26:00    15\n",
       "2013-11-08 04:20:00    18\n",
       "2015-03-11 16:11:00    14\n",
       "2015-09-28 14:53:00    18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[(df_test['svc_poly_preds']==0) & (df_test['label']==1)].groupby(by='date').agg(lambda x: len(x))['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2577   45]\n",
      " [ 166   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2622\n",
      "           1       0.31      0.11      0.16       186\n",
      "\n",
      "    accuracy                           0.92      2808\n",
      "   macro avg       0.62      0.55      0.56      2808\n",
      "weighted avg       0.90      0.92      0.91      2808\n",
      "\n",
      "[[848 105]\n",
      " [ 56   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       953\n",
      "           1       0.06      0.11      0.08        63\n",
      "\n",
      "    accuracy                           0.84      1016\n",
      "   macro avg       0.50      0.50      0.50      1016\n",
      "weighted avg       0.88      0.84      0.86      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = knn(n_neighbors=knn_neighbors)\n",
    "model.fit(X, y)\n",
    "\n",
    "preds_train = model.predict(scaled_train)\n",
    "preds = model.predict(scaled_test)\n",
    "\n",
    "uncertain_preds = None\n",
    "if use_uncertain:\n",
    "    uncertain_preds = model.predict(scaled_uncertain)\n",
    "\n",
    "set_preds(df_train, df_test, df_uncertain_test, preds_train, preds, uncertain_preds, f'knn_{knn_neighbors}')\n",
    "\n",
    "print(confusion_matrix(df_test['label'], df_test['knn_11_preds']))\n",
    "print(classification_report(df_test['label'], df_test['knn_11_preds']))\n",
    "\n",
    "if use_uncertain:\n",
    "    print(confusion_matrix(df_uncertain_test['label'], df_uncertain_test['knn_11_preds']))\n",
    "    print(classification_report(df_uncertain_test['label'], df_uncertain_test['knn_11_preds']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = knn_bagging(bootstrap=True,warm_start=True,bootstrap_features=True, max_features=1)\n",
    "model.fit(X, y)\n",
    "\n",
    "preds_train = model.predict(scaled_train)\n",
    "preds = model.predict(scaled_test)\n",
    "\n",
    "uncertain_preds = None\n",
    "if use_uncertain:\n",
    "    uncertain_preds = model.predict(scaled_uncertain)\n",
    "    \n",
    "set_preds(df_train, df_test, df_uncertain_test, preds_train, preds, uncertain_preds, f'knn_bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2589   33]\n",
      " [ 168   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      2622\n",
      "           1       0.35      0.10      0.15       186\n",
      "\n",
      "    accuracy                           0.93      2808\n",
      "   macro avg       0.65      0.54      0.56      2808\n",
      "weighted avg       0.90      0.93      0.91      2808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # set_preds(df_train, df_test, df_uncertain_test, preds_train, preds, uncertain_preds, f'knn_{knn_neighbors}')\n",
    "# print(confusion_matrix(df_train['label'], preds_train))\n",
    "# print(classification_report(df_train['label'], preds_train))\n",
    "\n",
    "# # set_preds(df_train, df_test, df_uncertain_test, preds_train, preds, uncertain_preds, f'knn_{knn_neighbors}')\n",
    "print(confusion_matrix(df_test['label'], df_test['knn_bagging_preds']))\n",
    "print(classification_report(df_test['label'], df_test['knn_bagging_preds']))\n",
    "\n",
    "# print(\"--------------------UNC --------------\")\n",
    "\n",
    "# print(confusion_matrix(df_uncertain_test['label'], uncertain_preds))\n",
    "# print(classification_report(df_uncertain_test['label'], uncertain_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1996-07-09T09:01:00.000000000', '2012-07-06T13:26:00.000000000',\n",
       "       '2001-04-06T19:13:00.000000000', '2015-03-11T16:11:00.000000000',\n",
       "       '2001-09-24T09:35:00.000000000', '2012-03-06T07:52:00.000000000',\n",
       "       '2013-11-08T04:20:00.000000000', '2012-07-04T09:47:00.000000000',\n",
       "       '2002-07-23T00:27:00.000000000', '2015-09-28T14:53:00.000000000',\n",
       "       '2012-03-05T19:27:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['poly', 'rbf']\n",
    "\n",
    "for i, kernel in enumerate(kernels):\n",
    "    svc1 = SVC(C=0.005, kernel=kernel)#, class_weight='balanced')\n",
    "    svc1.fit(X, y)\n",
    "\n",
    "    preds_train_svc = svc1.predict(scaled_train)\n",
    "    preds_test_svc = svc1.predict(scaled_test)\n",
    "\n",
    "    preds_unc_svc = None\n",
    "    if use_uncertain:\n",
    "        preds_unc_svc = model.predict(scaled_uncertain)\n",
    "\n",
    "    set_preds(df_train, df_test, df_uncertain_test, preds_train_svc, preds_test_svc, preds_unc_svc, f'svc_{kernel}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2596   26]\n",
      " [ 170   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      2622\n",
      "           1       0.38      0.09      0.14       186\n",
      "\n",
      "    accuracy                           0.93      2808\n",
      "   macro avg       0.66      0.54      0.55      2808\n",
      "weighted avg       0.90      0.93      0.91      2808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df_test['label'], df_test['svc_poly_preds']))\n",
    "print(classification_report(df_test['label'], df_test['svc_poly_preds']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = df_test[((df_test['svc_poly_preds']==1) & (df_test['label']==1)) | (df_test['label']==1)][['date', 'svc_poly_preds', 'label']].groupby('date').agg(sum)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10327     0]\n",
      " [    0   659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10327\n",
      "           1       1.00      1.00      1.00       659\n",
      "\n",
      "    accuracy                           1.00     10986\n",
      "   macro avg       1.00      1.00      1.00     10986\n",
      "weighted avg       1.00      1.00      1.00     10986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df_train['label'], df_train['svc_poly_preds']))\n",
    "print(classification_report(df_train['label'], df_train['svc_poly_preds']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(confusion_matrix(df_uncertain_test['label'], df_uncertain_test['svc_poly_preds']))\n",
    "# print(classification_report(df_uncertain_test['label'], df_uncertain_test['svc_poly_preds']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = df_test[(df_test['svc_poly_preds']==1) & (df_test['label'] == 0)]\n",
    "# g1 = fp .groupby(['Year','month','day','Hour','Minute','Seconds'])\n",
    "# for i,g in enumerate(g1.groups):\n",
    "#     gr = g1.get_group(g)\n",
    "#     print(f\"event: {'_'.join(str(i) for i in g)}, frames:\")\n",
    "#     print(gr.sort_values(by='frame')['frame'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      2622\n",
      "           1       0.35      0.09      0.14       186\n",
      "\n",
      "    accuracy                           0.93      2808\n",
      "   macro avg       0.64      0.54      0.55      2808\n",
      "weighted avg       0.90      0.93      0.91      2808\n",
      "\n",
      "[[2592   30]\n",
      " [ 170   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10327\n",
      "           1       1.00      1.00      1.00       659\n",
      "\n",
      "    accuracy                           1.00     10986\n",
      "   macro avg       1.00      1.00      1.00     10986\n",
      "weighted avg       1.00      1.00      1.00     10986\n",
      "\n",
      "[[10327     0]\n",
      " [    0   659]]\n"
     ]
    }
   ],
   "source": [
    "lr = logistic_reg()#max_iter=200, warm_start=True, tol=1e-1,solver='newton-cg')#class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "preds_train_lr = lr.predict(scaled_train)\n",
    "preds_test_lr = lr.predict(scaled_test)\n",
    "\n",
    "preds_unc_lr = None\n",
    "if use_uncertain:\n",
    "    preds_unc_lr = model.predict(scaled_uncertain)\n",
    "\n",
    "set_preds(df_train, df_test, df_uncertain_test, preds_train_lr, preds_test_lr, preds_unc_lr, f'logistic_regression')\n",
    "print(classification_report(df_test['label'], preds_test_lr))\n",
    "print(confusion_matrix(df_test['label'], preds_test_lr))\n",
    "\n",
    "print(classification_report(df_train['label'], preds_train_lr))\n",
    "print(confusion_matrix(df_train['label'], preds_train_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      2622\n",
      "           1       0.14      0.14      0.14       186\n",
      "\n",
      "    accuracy                           0.89      2808\n",
      "   macro avg       0.54      0.54      0.54      2808\n",
      "weighted avg       0.89      0.89      0.89      2808\n",
      "\n",
      "[[2465  157]\n",
      " [ 160   26]]\n"
     ]
    }
   ],
   "source": [
    "model = sgd(class_weight='balanced')\n",
    "model.fit(X, y)\n",
    "\n",
    "preds_train = model.predict(scaled_train)\n",
    "preds = model.predict(scaled_test)\n",
    "\n",
    "uncertain_preds = None\n",
    "if use_uncertain:\n",
    "    uncertain_preds = model.predict(scaled_uncertain)\n",
    "\n",
    "set_preds(df_train, df_test, df_uncertain_test, preds_train, preds, uncertain_preds, f'sgd')\n",
    "\n",
    "print(classification_report(df_test['label'],preds))\n",
    "print(confusion_matrix(df_test['label'],preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg & Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "if old_run:\n",
    "    gb_cols = ['part_of_quake','Year','month','day','event_idx','frame']\n",
    "else:   \n",
    "    gb_cols = ['part_of_quake','Year','month','day','Hour','Minute','Seconds','frame']\n",
    "\n",
    "cls_types = [f'knn_{knn_neighbors}', 'knn_bagging', 'svc_poly', 'svc_rbf','logistic_regression','sgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if has_tr_train and has_tr_test and not run_on_raw:\n",
    "    for i, cls in enumerate(cls_types):\n",
    "        df_train = df_train.groupby(gb_cols).apply(lambda df: set_custom_preds(df,cls))\n",
    "        df_test = df_test.groupby(gb_cols).apply(lambda df: set_custom_preds(df,cls))\n",
    "        if use_uncertain:\n",
    "            df_uncertain_test = df_uncertain_test.groupby(gb_cols).apply(lambda df: set_custom_preds(df, cls))\n",
    "    cls_types = cls_types \n",
    "    cls_types_any_avg = [f'any_{classtype}' for i, classtype in enumerate(cls_types)] + [f'avg_{classtype}' for i, classtype in enumerate(cls_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2592   30]\n",
      " [ 170   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      2622\n",
      "           1       0.35      0.09      0.14       186\n",
      "\n",
      "    accuracy                           0.93      2808\n",
      "   macro avg       0.64      0.54      0.55      2808\n",
      "weighted avg       0.90      0.93      0.91      2808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df_test['label'],df_test['logistic_regression_preds']))\n",
    "print(classification_report(df_test['label'],df_test['logistic_regression_preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(f'./out/builtpreds/{run_name}_train.csv',index=False)\n",
    "df_test.to_csv(f'./out/builtpreds/{run_name}_test.csv',index=False)\n",
    "\n",
    "if (use_uncertain):\n",
    "    df_uncertain_test.to_csv(f'./out/builtpreds/{run_name}_uncertain.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_tr_train:\n",
    "    df_train_raw = df_train[df_train['transform'] == 20]\n",
    "if  has_tr_test:\n",
    "    df_test_raw = df_test[df_test['transform'] == 20]\n",
    "if use_uncertain and has_tr_unc:\n",
    "    df_uncertain_raw = df_uncertain_test[df_uncertain_test['transform'] == 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C23_C24_july_12_rerun_without_smote'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "with open(f\"results_all_contrastive_{run_name}{'_raw' if run_on_raw else ''}.txt\", 'w') as f:\n",
    "    f.write(f\"transforms train: {'true' if has_tr_train else 'false'}\\n\")\n",
    "    f.write(f\"transforms test: {'true' if has_tr_test else 'false'}\\n\")\n",
    "    if use_uncertain:\n",
    "        f.write(f\"transforms unc: {'true' if has_tr_unc else 'false'}\\n\")\n",
    "    \n",
    "\n",
    "    for i, cls in enumerate(cls_types):\n",
    "        f.write(f\"\\n------{cls} {'raw' if run_on_raw else ''} based on {based_on}------\\n\")\n",
    " \n",
    "        f.write(\"\\nTrain:\\n\")\n",
    "        f.write(classification_report(df_train['label'], df_train[f'{cls}_preds']))\n",
    "        f.write(np.array2string(confusion_matrix(df_train['label'], df_train[f'{cls}_preds'])))\n",
    "        f.write(\"\\nTest:\\n\")\n",
    "        f.write(classification_report(df_test['label'], df_test[f'{cls}_preds']))\n",
    "        f.write(np.array2string(confusion_matrix(df_test['label'], df_test[f'{cls}_preds'])))\n",
    "        if use_uncertain:\n",
    "            f.write(\"\\nUncertain:\\n\")\n",
    "            f.write(classification_report(df_uncertain_test['label'], df_uncertain_test[f'{cls}_preds']))\n",
    "            f.write(np.array2string(confusion_matrix(df_uncertain_test['label'], df_uncertain_test[f'{cls}_preds'])))\n",
    "\n",
    "    if not run_on_raw:\n",
    "        for i, cls in enumerate(cls_types_any_avg):\n",
    "            f.write(f\"\\n------{cls} {'raw' if run_on_raw else ''} based on {based_on}------\\n\")\n",
    " \n",
    "            f.write(\"\\nTrain:\\n\")\n",
    "            f.write(classification_report(df_train_raw['label'], df_train_raw[f'{cls}_preds']))\n",
    "            f.write(np.array2string(confusion_matrix(df_train_raw['label'], df_train_raw[f'{cls}_preds'])))\n",
    "            f.write(\"\\nTest:\\n\")\n",
    "            f.write(classification_report(df_test_raw['label'], df_test_raw[f'{cls}_preds']))\n",
    "            f.write(np.array2string(confusion_matrix(df_test_raw['label'], df_test_raw[f'{cls}_preds'])))\n",
    "            if use_uncertain:\n",
    "                f.write(\"\\nUncertain:\\n\")\n",
    "                f.write(classification_report(df_uncertain_raw['label'], df_uncertain_raw[f'{cls}_preds']))\n",
    "                f.write(np.array2string(confusion_matrix(df_uncertain_raw['label'], df_uncertain_raw[f'{cls}_preds'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9ae8dc3ff7097afd6e5e4dada2a0358d51f170c946777b0dda73691ff3f53fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
